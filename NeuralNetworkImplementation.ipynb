{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworkImplementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcTdb+hkbhsqIlyIpdmDDy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drishtigulenia/data-science-Implementations/blob/main/NeuralNetworkImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBDD_WzTygzZ"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uignSuVZypk2",
        "outputId": "2d0d7eba-7502-4b17-d30e-c2595c1802b4"
      },
      "source": [
        "# input for layer having 3 input neurons and weights for inputs going into only 1 neuron\n",
        "inputs = [0,9,8]\n",
        "weights = [8,4,6]\n",
        "bias = 2\n",
        "output = inputs[0] * weights[0] + inputs[1] * weights[1] + inputs[2] * weights[2] + bias\n",
        "output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbq95VTZy_m8",
        "outputId": "a90ca943-cbfc-4fcd-ee04-04b9eb50fbc4"
      },
      "source": [
        "# input for layer having 4 input neurons and weights for inputs going into only 1 neuron\n",
        "inputs = [0,7,3,5]\n",
        "weights = [8,4,2,1]\n",
        "bias = 3\n",
        "output = inputs[0] * weights[0] + inputs[1] * weights[1] + inputs[2] * weights[2] + inputs[3] * weights[3] + bias\n",
        "output"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB6b1Hvbzvk5",
        "outputId": "4c497251-4ce3-46c3-df02-b6bd2ed9307b"
      },
      "source": [
        "# input for layer having 4 input neurons and weights for inputs going into 3 different neurons\n",
        "inputs = [8,4,6,3]\n",
        "\n",
        "# weight for 3 different neurons\n",
        "weights1 = [5.3, 7.7, 9,2, 3,4]\n",
        "weights2 = [5.6, 3.5, 2.3, 9.7]\n",
        "weights3 = [9.5, 4.5, 3.8, 6.9]\n",
        "\n",
        "# bias for 3 different neurons\n",
        "bias1 = 4\n",
        "bias2 = 6\n",
        "bias3 = 1\n",
        "\n",
        "# output in array for 3 neurons\n",
        "output = [inputs[0] * weights1[0] + inputs[1] * weights1[1] + inputs[2] * weights1[2] + inputs[3] * weights1[3] + bias1,\n",
        "          inputs[0] * weights2[0] + inputs[1] * weights2[1] + inputs[2] * weights2[2] + inputs[3] * weights2[3] + bias2,\n",
        "          inputs[0] * weights3[0] + inputs[1] * weights3[1] + inputs[2] * weights3[2] + inputs[3] * weights3[3] + bias3]\n",
        "output"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[137.2, 107.69999999999999, 138.5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a4OHII05JS",
        "outputId": "a3b1d29e-d959-4e28-9440-5720a8ca55b1"
      },
      "source": [
        "# rough of what we gonna do in next code area\n",
        "inputs = [1,2,3,4] # for this (list in python) the size would be (4,) (in numpy it is 1D array)\n",
        "weights = [[1,2,3,4],\n",
        "           [5,6,7,8],\n",
        "           [9,10,11,12]] # for this (list in python) the size would be (3,4) (in numpy it is 2D array)\n",
        "bias = [1, 2, 3] # for this (list in python) the size would be (3,) (in numpy it is 1D array)\n",
        "output = np.dot(weights, inputs) + bias\n",
        "\n",
        "# batch inputs \n",
        "input = [[1,2,3,4],\n",
        "         [5,6,7,8],\n",
        "         [9,10,11,12]]\n",
        "\n",
        "layer1_output = np.dot(input, np.array(weights).T) + bias\n",
        "# np.dot(weights, inputs) = weights[0] * input + weights[1] * input + weights[2] * input\n",
        "output\n",
        "weights2 = [[0.8,2,1.3],\n",
        "           [0.6,-1,0.1],\n",
        "           [0.5,0.1,1]]\n",
        "\n",
        "bias2 = [1, 0, 2]\n",
        "\n",
        "layer2_output = np.dot(layer1_output, np.array(weights2).T) + bias2\n",
        "layer2_output"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 316.7,  -42.1,  137.7],\n",
              "       [ 775.1, -105.3,  336.1],\n",
              "       [1233.5, -168.5,  534.5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0NQ6zvMcoxX",
        "outputId": "e2ed9e67-fed0-4533-c015-0de7b4b56ba7"
      },
      "source": [
        " X = [[1,2,3,2.5],\n",
        "      [2.0,5.0,-1.0,2.0],\n",
        "      [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "def create_dataset(hm, varience, step=2, correlation='neg'):\n",
        "  ys = []\n",
        "  val = 1\n",
        "  for i in range(hm):\n",
        "    y = val + random.randrange(-varience, varience)\n",
        "    ys.append(y)\n",
        "    if correlation == 'pos':\n",
        "      val+=step\n",
        "    elif correlation == 'neg':\n",
        "      val-=step\n",
        "  xs = [i for i in range(len(ys))]\n",
        "  return np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)\n",
        "\n",
        "# visualizing dataset\n",
        "X, ys = create_dataset(20,10,2,'pos')\n",
        "ys"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6., -3., 13., -3., 18., 10.,  5., 16., 18., 21., 15., 19., 30.,\n",
              "       33., 37., 31., 35., 37., 36., 43.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vipmWP81YMrD",
        "outputId": "0d2c6f19-c42a-409d-b886-a0393a0ed00d"
      },
      "source": [
        "class Layer_Dense:\n",
        "  def __init__(self, n_input, n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_input, n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "class Activation_ReLu:\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0,inputs)\n",
        "\n",
        "class Activation_Softmax:\n",
        "  def forward(self, inputs):\n",
        "    exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "    self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "class Loss:\n",
        "  def calculate(self, output, y_true):\n",
        "    sample_losses = self.forward(output, y_true)\n",
        "    return np.mean(sample_losses)\n",
        "\n",
        "class Loss_Cross_Entropy(Loss):\n",
        "  def forward(self, y_pred, y_true):\n",
        "    samples = len(y_pred)\n",
        "    y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)\n",
        "    # y_true = np.array(y_true)\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
        "\n",
        "    negative_log_likelihood = -np.log(correct_confidences)\n",
        "    return negative_log_likelihood\n",
        "  # def forward(self, y_pred, y_true):\n",
        "    # predictions = np.argmax(y_pred, axis=1)\n",
        "    # count = 0\n",
        "    # predictions = predictions - y_true;\n",
        "    # for i in range(np.size(predictions)):\n",
        "    #   if predictions[i] != 0:\n",
        "    #       count+=1\n",
        "    #       print(predictions[i])\n",
        "    # return count/np.size(predictions)\n",
        "\n",
        "\n",
        "layer1 = Layer_Dense(20, 5)\n",
        "layer2 = Layer_Dense(5,2)\n",
        "activation1 = Activation_ReLu()\n",
        "activation2 = Activation_Softmax()\n",
        "\n",
        "layer1.forward(X)\n",
        "activation1.forward(layer1.output)\n",
        "\n",
        "layer2.forward(activation1.output)\n",
        "activation2.forward(layer2.output)\n",
        "\n",
        "loss = Loss_Cross_Entropy()\n",
        "not_gud = loss.calculate(activation2.output, ys);\n",
        "print(not_gud)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6606447103408729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qapQzKIvplqa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}